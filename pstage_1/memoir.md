# 회고록

Naver Connect 재단에서 운영하는 Boostcamp AI Tech의 첫 번째 대회인 마스크 착용 분류 대회에 참여하게 되었다. 나는 이번이 세 번째 대회 참가인데, 지난 두 번의 대회에서는 그저 참여에만 의의를 두었었기 때문에 이번 대회에서는 그간 공부하고 성장한 것을 조금이나마 입증하는 겸, 무조건 순위권에 들어야겠다는 목표를 가지고 대회에 임하게 되었다.

결과적으로는 38팀 중 13위에 그쳤고, 처음 목표에 비해서는 너무나도 아쉬운 결과지만 지난 두 번의 대회에 비하면 매우 주도적으로 대회에 임했고 많은 코드를 작성하고 실험을 하며 어느정도 인공지능 대회라는 프로세스에 익숙해질 수 있었다는 것에서 나름 만족스러운 대회였던 것 같다.

## Timetable (21.08.23 ~ 21.09.02)

- 08.23 ~ 08.24: EDA 및 Data Labeling
- 08.25 ~ 08.26: Baseline 코드 작성
- 08.27 ~ 08.30: Augmentation 적용 및 실험
- 08.31 ~ 09.01: 개별모델 분리 및 앙상블
- 09.02: 외부데이터셋 추가 및 최종제출

## 대회 전략

이번 대회는 2주동안 팀 단위로 진행되었는데, 1주차는 개인제출, 2주차는 팀제출로 진행되었다. 

팀원들이 모두들 순위에 욕심이 있었기 때문에 1주차에는 데이터 EDA에 집중하며 노이즈나 Labeling이 잘못된 데이터를 최대한 발견하고 수정하는 쪽으로 진행했으며, 2주차에는 최대한 성능을 끌어올리는 식으로 계획을 가져갔다.

하지만 깃과 협업문화에 익숙하지 않은 팀원들이 있었고, 내 서버가 계속 죽는 불상사가 있었기 때문에 Github를 이용한 프로젝트 관리에 어려움이 있었고 더 나은 환경에서 서로의 작업을 상세하게 공유하는 것이 생각보다 쉽지 않았다.

결국에는 전략이랄 것도 없이 그저 각자의 환경에서 서로다른 실험을 계속하는 것밖엔 이루어지지 않았는데 이것이 가장 큰 아쉬움으로 남는 것 같다.

## 데이터 분석과 EDA

데이터에는 예상대로 노이즈가 몇 군데 있었다. 애초에 잘 정제되어있는 데이터였기 때문에 많지는 않았으나 남자를 여자로, 여자를 남자로 적어놓은 데이터가 있는가 하면, 마스크를 끼고 있는데 파일이름에는 마스크를 착용하지 않았다고 나와있는 것들이 존재했다. 다행히 AIStage의 토론게시판과 팀원들의 도움으로 모든 노이즈를 찾아서 제거해줄 수 있었다.

EDA 과정에서도 토론게시판과 팀원들의 도움을 많이 받았다. 특히 데이터가 잘 정제되어 있다는 것을 해당 단계에서 알아차릴 수 있었으며 마스크를 잘못 착용한 데이터에는 턱스크는 물론 마스크를 눈에 착용한다던지 하는 괴상한 사진도 있었다. 가장 좋은 분석 중 하나는 데이터의 분포를 시각화로 알아낼 수 있었다는 것인데, 60세 이상 데이터는 60세만 존재하였고 해당 데이터가 가장 적은 비율로 존재했기 때문에 '나이'를 제대로 예측하는 것이 가장 중요하겠다는 판단을 할 수 있었다.

지금까지는 Visualization에 대한 일종의 편견이 있었기 때문에 오히려 배우려고 들지 않았던 것 같은데, 이번 대회를 통해서 그 중요성을 인지할 수 있었던 것 같다. Seaborn과 Matplotlib을 잘 사용하는 것이 실무에서도 굉장한 도움을 얻을 수 있을 것이라고 생각된다.

## 베이스라인 코드 및 협업환경 구성

팀원들과 베이스라인 코드로 U Stage 에서 배웠던 [파이토치 템플릿](https://github.com/victoresque/pytorch-template)을 사용하기로 했다. 워낙 우리 조에서 하는 것이 많다 보니 다들 파이토치 템플릿에 익숙하지가 않았기 때문에 간단하게 바로 실험을 돌려볼 수 있는 베이스라인 코드를 잘 작성하는 것이 생각보다 매우 어려웠다. 구조적으로 잘 짜여있고 모듈화가 잘 되어있기 때문에 파이토치 템플릿을 사용하기로 했었는데, 지금 생각해보면 이것도 더 좋은 성능을 내지 못한 이유 중 하나일 것으로 생각된다.

그렇게 생각하는 원인은 아래와 같다.

1. 협업을 위한 환경 Fix가 어렵다.
2. 모델에 Config 파일 정보를 같이 저장하기 때문에 Config파일 없이 모델을 불러올 수가 없다.
3. Remote 환경으로 작업하기 때문에 CLI에 익숙하지 않으면 원하는 대로 파이썬 스크립트를 실행해보기가 어렵다.
4. 모듈화가 잘 되어있지만 의존성을 가지는 함수들이 있기 때문에 구조를 제대로 파악하지 않으면 원하는대로 커스텀하기가 어렵다.

대부분 대회에서는 빠른 커스터마이징과 실험을 통해 계속해서 성능을 올리는 것을 목표로 한다. 하지만 우리 조원들중에는 CLI와 Git을 처음 써보는 팀원도 있었고 파이썬 코드에 익숙하지 않은 팀원도 있었기 때문에 파이토치 템플릿같은 구조를 완벽하게 이해하지 못해서 내가 만든 베이스라인을 팀원들이 이해하고 실행하는데 꽤 오랜 시간을 소비하게 되었다.

Dot ENV 혹은 이미지 경로 등 MetaData와 환경을 고정할 수 있는 요소들을 미리 감안하지 않은 것, 그리고 애초에 쉽게 구조를 파악할 수 없는 템플릿을 사용하여 많은 실험을 못하게 된 것을 다음 협업때부터는 고려할 수 있도록 해보아야 할 것 같다. 또한 Python 스크립트도 좋지만 Jupyter 환경에서 돌아가는 코드를 작성하는 것도 매우 좋을 것 같다..!=

## 모델링과 실험

이번 P Stage에서 협업을 제외하고 가장 큰 아쉬움으로 다가오는 것은 실험일지를 체계적으로 정리하지 않았고, 파일관리를 제대로 하지 않았다는 것이다. 총 100기가의 저장공간 중 실제 사용할 수 있는 용량은 약 6-70 기가정도였는데 Epochs 단위마다 모델을 저장해놓았기 때문에 계속해서 서버용량에 제약을 받게 되었다. 그리고 점점 끝이 다가올수록 성능향상도 안되고 마음도 급해져서 잘 확인하지도 않고 파일을 삭제하는 것을 반복했었는데, 그러다가 최고 성능을 낸 모델까지 지워버리는 참사가 발생했다. 최종 제출 직전에 확인하고 현재 최고 스코어가 재현이 안된다는 것을 알았을 때 정말, 그 좌절감은 이루말할 수 없다.

그리고 기존 실험하고 있던 모델과 하이퍼파라미터를 픽스하고 여러가지 개선방안 중에서 하나씩 적용해보면서 성능이 오른 것을 취하는 전략이 가장 좋았을 것 같은데, 그렇게 하지 않았기 때문에 분명히 성능이 오를 요소들을 제대로 포착하지 못했다. 예를들어 Augmentation이 적용된 이미지들을 만들고 거기에 Augmix 등 여러 Augmentaiton을 Soft하게 적용하여 실험했는데 성능이 떨어졌다. 이 때 데이터를 추가해서 성능이 떨어진건지, 아니면 다른 Augmentation 때문에 성능이 떨어진 건지 알지 못했다.

실험일지를 잘 작성하고 기존에서 성능을 올리는 쪽으로만 전략을 취할 수 있도록 다음 대회부터는 일지를 작성해봐야할 것 같다.

또한 위의 이야기와 더불어 실험을 했던 코드를 체계적으로 정리했으면 어땠을까 싶다. 모듈화가 잘 되어 있는 템플릿을 사용하면서 여러 실험을 할 때는 대부분 하드코딩 아니면 모듈화를 시키지 않은 채 코드를 작성했기 때문에 실험환경을 바꿀 때마다 피로도가 굉장히 컸다. 그리고 Wandb와 Tensorboard 등 시각화 도구들을 사용할 때 Runtime 에러가 발생했을 때도 모든 로그를 기록하게 해서 서버 용량이 굉장히 빠르게 차올랐는데, 이 부분 역시 쉽게 적용여부를 결정할 수 있도록 만들었으면 더 좋았을 것 같다.

## 총평

근본없이 너무 무지성 실험을 반복했던 것 같다. 결국 그렇게 하다가 성능이 오르긴 했었지만, 그렇게 성능이 올랐을 때의 환경을 픽스하지 못하고 다른 추가적인 것들을 적용하다 보니 최종스코어를 재현할 수도 없고 오히려 성능이 떨어지는 상황이 수도없이 반복되었다.

또한 계속 협업의 중요성을 말하고 다녔지만 결국엔 나부터도 버전관리와 공유에 소홀했다. 다시금 그 중요성을 생각하면서 같은 실수는 반복하지 않도록 노력해야겠다.